{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d06548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fo colab - ignore on local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c883e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
    "!ls /mydrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0f8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /content/gdrive/MyDrive/UrbanSound_mini.zip /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b61af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aafd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip UrbanSound_mini.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5986cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd1e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./UrbanSound/data\"\n",
    "POSITIVE_CLASS = \"gun_shot\"\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 2.0\n",
    "MFCC_NUM = 40\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "N_MELS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e7a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_file(file_path, target_sr=SAMPLE_RATE, duration=DURATION):\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(file_path)\n",
    "        audio = audio.set_channels(1)\n",
    "        audio = audio.set_frame_rate(target_sr)\n",
    "        samples = np.array(audio.get_array_of_samples()).astype(np.float32) / (2**15)\n",
    "        target_length = int(target_sr * duration)\n",
    "        if len(samples) < target_length:\n",
    "            samples = np.pad(samples, (0, target_length - len(samples)))\n",
    "        else:\n",
    "            samples = samples[:target_length]\n",
    "        return samples, target_sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def extract_features(audio, sr=SAMPLE_RATE, n_mfcc=MFCC_NUM, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfccs = librosa.util.normalize(mfccs)\n",
    "    mel = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    mel = librosa.power_to_db(mel, ref=np.max)\n",
    "    mel = librosa.util.normalize(mel)\n",
    "    features = np.stack([mfccs, mel[:n_mfcc, :]], axis=-1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_binary(dataset_path, positive_class=\"gun_shot\", max_files_per_class=None):\n",
    "    features = []\n",
    "    labels = []\n",
    "    all_classes = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "    for class_name in all_classes:\n",
    "        class_dir = os.path.join(dataset_path, class_name)\n",
    "        audio_files = [f for f in os.listdir(class_dir) if f.endswith(('.wav', '.mp3', '.aif', '.flac'))]\n",
    "        if max_files_per_class:\n",
    "            audio_files = audio_files[:max_files_per_class]\n",
    "        for audio_file in tqdm(audio_files, desc=f\"Processing {class_name}\"):\n",
    "            file_path = os.path.join(class_dir, audio_file)\n",
    "            audio, sr = load_audio_file(file_path)\n",
    "            if audio is None:\n",
    "                continue\n",
    "            try:\n",
    "                feature = extract_features(audio, sr)\n",
    "                features.append(feature)\n",
    "                labels.append(1 if class_name == positive_class else 0)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {str(e)}\")\n",
    "                continue\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda7716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "X, y = load_dataset_binary(DATASET_PATH, positive_class=POSITIVE_CLASS, max_files_per_class=200)\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"No data was loaded. Please check your dataset path and file formats.\")\n",
    "print(f\"Loaded {len(X)} samples\")\n",
    "print(f\"Feature shape: {X[0].shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d00c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "model = build_model(input_shape)\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f2d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd3ac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating the model...\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int).flatten()\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Gunshot', 'Gunshot'], yticklabels=['Not Gunshot', 'Gunshot'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=['Not Gunshot', 'Gunshot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example: y_true and y_pred\n",
    "# y_true = [0, 1, 0, 1, ...]\n",
    "# y_pred = [0, 1, 1, 0, ...]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "# cm layout for binary classification:\n",
    "# [[TN, FP],\n",
    "#  [FN, TP]]\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                 xticklabels=['Not Gunshot', 'Gunshot'], \n",
    "                 yticklabels=['Not Gunshot', 'Gunshot'])\n",
    "\n",
    "# Annotate with TP, FP, TN, FN\n",
    "ax.text(0.5, 0.5, 'TN', ha='center', va='center', color='blue', fontsize=14)\n",
    "ax.text(1.5, 0.5, 'FP', ha='center', va='center', color='blue', fontsize=14)\n",
    "ax.text(0.5, 1.5, 'FN', ha='center', va='center', color='blue', fontsize=14)\n",
    "ax.text(1.5, 1.5, 'TP', ha='center', va='center', color='blue', fontsize=14)\n",
    "\n",
    "plt.title('Confusion Matrix with TP, FP, TN, FN')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42578f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab657394",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"gunshot_cnn_model.h5\")  # or use .keras for the new format\n",
    "model.save('gunshot_cnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc40a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model for inference : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"gunshot_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290c2c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for audio stream processing: [not tested] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "DURATION = 2.0  # seconds\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    # indata: shape (frames, channels)\n",
    "    audio = indata[:, 0]  # mono\n",
    "    # Preprocess and extract features as in training\n",
    "    features = extract_features(audio, SAMPLE_RATE)\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "    prediction = model.predict(features)[0][0]\n",
    "    if prediction > 0.5:\n",
    "        print(\"Gunshot detected!\")\n",
    "\n",
    "# Start streaming\n",
    "with sd.InputStream(channels=1, samplerate=SAMPLE_RATE, callback=audio_callback, blocksize=int(SAMPLE_RATE * DURATION)):\n",
    "    print(\"Listening for gunshots...\")\n",
    "    while True:\n",
    "        pass  # Keep the stream alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c2148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "MODEL_PATH = \"gunshot_cnn_model.keras\"\n",
    "AUDIO_PATH = \"/content/UrbanSound_mini/data/jack_hammer/105029.wav\"  # Change to your file\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 2.0  # seconds\n",
    "MFCC_NUM = 40\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "N_MELS = 128\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# --- LOAD MODEL ---\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# --- FEATURE EXTRACTION (same as training) ---\n",
    "def extract_features(audio, sr=SAMPLE_RATE, n_mfcc=MFCC_NUM, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfccs = librosa.util.normalize(mfccs)\n",
    "    mel = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    mel = librosa.power_to_db(mel, ref=np.max)\n",
    "    mel = librosa.util.normalize(mel)\n",
    "    features = np.stack([mfccs, mel[:n_mfcc, :]], axis=-1)\n",
    "    return features\n",
    "\n",
    "# --- LOAD AND PREPROCESS AUDIO FILE ---\n",
    "audio, sr = librosa.load(AUDIO_PATH, sr=SAMPLE_RATE, mono=True)\n",
    "target_length = int(SAMPLE_RATE * DURATION)\n",
    "if len(audio) < target_length:\n",
    "    audio = np.pad(audio, (0, target_length - len(audio)))\n",
    "else:\n",
    "    audio = audio[:target_length]\n",
    "\n",
    "features = extract_features(audio, SAMPLE_RATE)\n",
    "features = np.expand_dims(features, axis=0)  # Add batch dimension\n",
    "\n",
    "# --- INFERENCE ---\n",
    "prob = model.predict(features)[0][0]\n",
    "if prob > THRESHOLD:\n",
    "    print(f\"Gunshot detected! (confidence: {prob:.2f})\")\n",
    "else:\n",
    "    print(f\"Not gunshot (confidence: {1-prob:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more : \n",
    "https://github.com/hasnainnaeem/Gunshot-Detection-in-Audio/blob/master/US8K-Binary%20Visualization%2C%20Training%20%26%20Predictions-updated.ipynb"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
